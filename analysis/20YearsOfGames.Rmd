---
title: "20YearsOfGames"
output:
  html_notebook: default
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
load.libraries <- c('readr','caret','ggplot2','dplyr','e1071')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependences = TRUE)
sapply(load.libraries, require, character = TRUE)

df <- read_csv("./data/20-years-of-games.csv", 
                               col_types = cols(url = col_skip(),
                                                release_month = col_integer(),
                                                score = col_number()))
df$score_phrase <- as.factor(df$score_phrase)
df$platform <- as.factor(df$platform)
df$editors_choice <- as.factor(df$editors_choice)
df$genre <- as.factor(df$genre)
df$release_date <- as.Date(with(df,paste(release_year,release_month,release_day,sep="-")),"%Y-%m-%d")
df = df[which(df$release_date!= as.Date("1970-01-01")),]
drop <- c("release_year","release_month","release_day")
df_p <- df[,!(names(df) %in% drop)]

df_total <- df_p %>% 
  group_by(platform) %>%
  summarise(count = n()) %>%
  top_n(count,n = 10)
```
## Introduction
In this document we look to analyse the data - 20 years of Games. A summary of the fields available is as shown below. As part of this report, we are going to describe the dataset, split the data into a test and training set and predict the likelihood that a game was made an editor's choice. In this particular example, we'll make use of the following R packages readr, ggplot2, dplyr, and caret

## Summaries
The data object is complex. It contains of the following columns - `r colnames(df)`. The columns `r drop` were combinded to form release date. There are over `r length(df_p$title)` titles for `r length(unique(df_p$platform))` different platforms and `r length(unique(df_p$genre))` genre of games for the past `r max(df$release_year)-min(df$release_year)`years. An overall summary of the dataset includes as follows
```{r }
summary(df_p)
```
An overall trend of the number of games during the years can be shown as below. As is visible from the graph, the PC gaming industry once had taken off hasn't looked back.

``` {r }
df_plot = left_join(df_total,df,by ="platform") %>% 
  group_by(platform,release_year) %>%
  summarise(count = n()) %>%
  group_by(platform) %>%
  arrange(release_year) %>%
  mutate(csum = cumsum(count))

ggplot(df_plot, aes(x=release_year, y = csum, colour = platform)) +
  geom_point() +
  geom_line() +
  theme(legend.position = "bottom")

```
## Predictive analysis
The aim of the predictive analysis is to calculate the likelihood that a game made was an editor's choice. This is a classification type problem, and there are two popular methods to resolve this

* Logistic regression
* Support vector machine regression

### Logistic Regression
The dataframe will be split into training, testing. The data is split to 60:40 for training and testing.The reason for this choice of split is to better understand the underlying distribution and then test the results with the remaining 40% of the data.
```{r }
df_t <- df_p[complete.cases(df_p),]
df_t$editors_choice <- as.character(df_t$editors_choice)
train <-createDataPartition(y = 1:nrow(df_t),p = 0.6, list = FALSE)
training <- df_t[train,]
testing <- df_t[-train,]
```
The model is trained to test for the following formula `formula (editors_choice ~ platform + genre+ score_phrase + score)` using logistic regression.
```{r include=FALSE, cache=FALSE}
mod_fit1 <- train(editors_choice ~ platform + genre + score_phrase + score, data = training, method = "glm", family = "binomial", na.action = na.exclude)
predictions = predict(mod_fit1,newdata = testing)
```
It appears there's a relationship between the editor's choice an the score received by the games. The best way to check if the predictions match the 
```{r }
t1 <- confusionMatrix(predictions, testing$editors_choice)
print(t1)
```
###using Support vector machine
```{r include=FALSE, cache=FALSE}
mod_fit2 <- train(editors_choice ~ platform + genre + score_phrase + score, data = training, method = "svmLinearWeights", na.action = na.exclude)
predictions2 = predict(mod_fit2,newdata = testing)
```

```{r }
t2 <- confusionMatrix(predictions2, testing$editors_choice)
print(t2)
```